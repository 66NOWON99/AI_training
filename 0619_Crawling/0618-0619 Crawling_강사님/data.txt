텐서 플로우 블로그 (Tensor ≈ Blog)
머신러닝(Machine Learning), 딥러닝(Deep Learning) 그리고 텐서(Tensor) 또 파이썬(Python)
컨텐츠로 건너뛰기
Home 머신러닝 무료 강의
핸즈온 머신러닝 2 (유튜브)
 
핸즈온 머신러닝 2 (인프런)
 
Do It! 딥러닝 입문 (유튜브)
 
Do It! 딥러닝 입문 (구름 에듀)
 케라스 딥러닝 핸즈온 머신러닝 파이썬 머신러닝 회오리 파이썬 Lectures Books Me
1. 딥러닝이란 무엇인가?
베타테스터 실습 후기 | 목차 | 1.2 딥러닝 이전: 머신 러닝의 간략한 역사

 

지난 몇 년간 인공 지능Artificial Intelligence, AI은 미디어에서 경쟁적으로 보도하는 주제였습니다. 머신 러닝machine learning, 딥러닝deep learning, AI에 대한 기사가 쏟아져 나왔으며, 기술적으로 이해가 부족한 글도 있었습니다. 우리는 지능적인 챗봇chatbot, 자율 주행 자동차, 가상 비서가 있는 미래를 기대합니다. 직업이 줄고 대부분의 경제 활동을 로봇이나 AI 에이전트가 수행할 미래는 이따금 어둡게 그려질 때도 있고, 어떨 때는 유토피아처럼 그려지기도 합니다. 현재 그리고 미래의 머신 러닝 기술자들은 잡음 속에서 제대로 된 신호를 잡아내듯이 과장된 뉴스 기사 속에서 세상을 바꿀 기술 발전을 알아차릴 수 있어야 합니다. 우리의 미래가 달려 있으며, 이 미래는 여러분이 왕성하게 활동할 미래입니다. 이 책을 읽고 나면 여러분은 AI 에이전트를 개발할 수 있는 사람들 중 하나일 것입니다. “딥러닝이 지금까지 거둔 성과는 무엇인가요? 얼마나 중요한가요? 어디를 향해 가고 있나요? 과장된 선전을 믿어도 될까요?”에 대한 답을 찾아보겠습니다.

이 장에서 인공 지능과 머신 러닝, 딥러닝에 대한 필수적인 개념을 소개합니다.

 

1.1 인공 지능과 머신 러닝, 딥러닝
먼저 AI를 언급할 때 사용하는 용어에 대해 명확히 정의할 필요가 있습니다. 인공 지능, 머신 러닝, 딥러닝은 무엇일까요?(그림 1-1 참고) 이들이 어떻게 서로 연관되어 있나요?

028
그림 1-1 인공 지능, 머신 러닝 그리고 딥러닝

 

1.1.1 인공지능
인공 지능은 1950년대에 초기 컴퓨터 과학 분야의 일부 선각자들이 “컴퓨터가 ‘생각’할 수 있는가?”라는 질문을 하면서 시작되었습니다. 이 질문의 답은 오늘날에도 여전히 찾고 있습니다. 이 분야에 대한 간결한 정의는 다음과 같습니다. 보통의 사람이 수행하는 지능적인 작업을 자동화하기 위한 연구 활동입니다. 이처럼 AI는 머신 러닝과 딥러닝을 포괄하는 종합적인 분야입니다. 또 학습 과정이 전혀 없는 다른 방법도 많이 포함하고 있습니다. 예를 들어 초기 체스 프로그램은 프로그래머가 만든 하드코딩된 규칙만 가지고 있었고 머신 러닝으로 인정받지 못했습니다. 아주 오랜 기간 동안 많은 전문가는 프로그래머들이 명시적인 규칙을 충분하게 많이 만들어 지식을 다루면 인간 수준의 인공 지능을 만들 수 있다고 믿었습니다. 이런 접근 방법을 심볼릭 AIsymbolic AI라고 하며 1950년대부터 1980년대까지 AI 분야의 지배적인 패러다임이었습니다. 1980년대 전문가 시스템expert system의 호황으로 그 인기가 절정에 다다랐습니다.

심볼릭 AI가 체스 게임처럼 잘 정의된 논리적인 문제를 푸는 데 적합하다는 것이 증명되었지만, 이미지 분류, 음성 인식, 언어 번역 같은 더 복잡하고 불분명한 문제를 해결하기 위한 명확한 규칙을 찾는 것은 아주 어려운 일입니다. 이런 심볼릭 AI를 대체하기 위한 새로운 방법이 등장했는데, 바로 머신 러닝입니다.

 

1.1.2 머신 러닝
영국 빅토리아 시대의 에이다 러브레이스Ada Lovelace, 1는 최초의 기계적 범용 컴퓨터인 해석 기관Analytical Engine을 발명한 찰스 배비지Charles Babbage의 친구이자 동료였습니다. 선견지명이 있어 시대를 많이 앞섰지만 1830년대와 1840년대부터 해석 기관이 범용 컴퓨터로 설계된 것은 아닙니다. 범용 컴퓨터란 개념이 아직 정의되지 않은 때였습니다. 단지 해석학mathematical analysis 분야의 계산을 자동화하기 위해 기계적인 연산을 사용하는 방법이었을 뿐입니다. 그래서 이름이 해석 기관입니다. 1843년 에이다 러브레이스는 이 발명에 대해 다음과 같이 언급했습니다. “해석 기관이 무언가를 새롭게 고안해 내는 것은 아닙니다. 우리가 어떤 것을 작동시키기 위해 어떻게 명령할지 알고 있다면 이 장치는 무엇이든 할 수 있습니다. …… 이런 능력은 우리가 이미 알고 있는 것을 유용하게 사용할 수 있도록 도와줄 것입니다.

AI 선구자인 앨런 튜링Alan Turing은 1950년에 튜링 테스트Turing test와 AI의 주요 개념을 소개한 그의 기념비적인 논문 “Computing Machinery and Intelligence”2에서 ‘러브레이스의 반론’Lady Lovelace’s objection, 3으로 이 논평을 인용했습니다. 튜링은 에이다 러브레이스의 말을 인용했지만 범용 컴퓨터가 학습과 창의력을 가질 수 있는지 숙고한 후 가능한 일이라고 결론을 냈습니다.

머신 러닝은 이런 질문에서부터 시작됩니다. “우리가 어떤 것을 작동시키기 위해 ‘어떻게 명령할지 알고 있는 것’ 이상을 컴퓨터가 처리하는 것이 가능한가? 그리고 특정 작업을 수행하는 법을 스스로 학습할 수 있는가? 컴퓨터가 우리를 놀라게 할 수 있을까? 프로그래머가 직접 만든 데이터 처리 규칙 대신 컴퓨터가 데이터를 보고 자동으로 이런 규칙을 학습할 수 있을까?”

이 질문은 새로운 프로그래밍 패러다임의 장을 열었습니다. 전통적인 프로그래밍인 심볼릭 AI의 패러다임에서는 규칙(프로그램)과 이 규칙에 따라 처리될 데이터를 입력하면 해답이 출력됩니다(그림 1-2 참고). 머신 러닝에서는 데이터와 이 데이터로부터 기대되는 해답을 입력하면 규칙이 출력됩니다. 이 규칙을 새로운 데이터에 적용하여 창의적인 답을 만들 수 있습니다.

030
그림 1-2 머신 러닝: 새로운 프로그래밍 패러다임

머신 러닝 시스템은 명시적으로 프로그램되는 것이 아니라 훈련training됩니다. 작업과 관련 있는 많은 샘플을 제공하면 이 데이터에서 통계적 구조를 찾아 그 작업을 자동화하기 위한 규칙을 만들어 냅니다. 예를 들어 여행 사진을 태깅하는 일을 자동화하고 싶다면, 사람이 이미 태그해 놓은 다수의 사진 샘플을 시스템에 제공해서 특정 사진에 태그를 연관시키기 위한 통계적 규칙을 학습할 수 있을 것입니다.

머신 러닝은 1990년대 들어와서야 각광을 받기 시작했지만, 고성능 하드웨어와 대량의 데이터셋이 가능해지면서 금방 AI에서 가장 인기 있고 성공적인 분야가 되었습니다. 머신 러닝은 수리 통계와 밀접하게 관련되어 있지만 통계와 다른 점이 몇 가지 있습니다. 먼저 머신 러닝은 통계와 달리 보통 대량의 복잡한 데이터셋(예를 들어 몇 만 개의 픽셀로 구성된 이미지가 수백만 개가 있는 데이터셋)을 다루기 때문에 베이지안 분석Bayesian analysis 같은 전통적인 통계 분석 방법은 현실적으로 적용하기 힘듭니다. 이런 이유 때문에 머신 러닝, 특히 딥러닝은 수학적 이론이 비교적 부족하고(어쩌면 아주 부족하고) 엔지니어링 지향적입니다. 이런 실천적인 접근 방식 때문에 이론보다는 경험을 바탕으로 아이디어가 증명되는 경우가 많습니다.4

 

1.1.3 데이터에서 표현을 학습하기
딥러닝을 정의하고 다른 머신 러닝 방식과의 차이점을 이해하기 위해 먼저 머신 러닝 알고리즘이 하는 일이 무엇인지 알아야 합니다. 머신 러닝은 샘플과 기댓값이 주어졌을 때 데이터 처리 작업을 위한 실행 규칙을 찾는 것입니다. 머신 러닝을 하기 위해서는 세 가지가 필요합니다.

입력 데이터 포인트: 예를 들어 주어진 문제가 음성 인식이라면, 이 데이터 포인트는 사람의 대화가 녹음된 사운드 파일입니다. 만약 이미지 태깅에 관한 작업이라면 데이터 포인트는 사진이 됩니다.
기대 출력: 음성 인식 작업에서는 사람이 사운드 파일을 듣고 옮긴 글입니다. 이미지 작업에서 기대하는 출력은 ‘강아지’, ‘고양이’ 등과 같은 태그입니다.
알고리즘의 성능을 측정하는 방법: 알고리즘의 현재 출력과 기대 출력 간의 차이를 결정하기 위해 필요합니다. 측정값은 알고리즘의 작동 방식을 교정하기 위한 신호로 다시 피드백됩니다. 이런 수정 단계를 학습learning이라고 말합니다.
머신 러닝 모델은 입력 데이터를 의미 있는 출력으로 변환합니다. 이것이 알고 있는 입력과 출력의 샘플로부터 학습하는 과정입니다. 그렇기 때문에 머신 러닝과 딥러닝의 핵심 문제는 의미 있는 데이터로의 변환입니다. 다시 말하면 입력 데이터를 기반으로 기대 출력에 가깝게 만드는 유용한 표현representation을 학습하는 것입니다. 여기에서 표현이란 무엇일까요? 핵심은 데이터를 인코딩encoding하거나 묘사하기 위해 데이터를 바라보는 다른 방법입니다. 예를 들어 컬러 이미지는 RGB 포맷(빨간색-녹색-파란색 )이나 HSV 포맷(색상-채도-명도)으로 인코딩될 수 있습니다. 이들은 같은 데이터의 두 가지 다른 표현입니다. 어떤 표현으로는 해결하기 힘든 문제가 다른 표현으로는 쉽게 해결될 수 있습니다. 예를 들어 ‘이미지에 있는 모든 빨간색 픽셀을 선택’하는 문제는 RGB 포맷에서는 쉽습니다. 반면에 ‘이미지의 채도를 낮추는’ 것은 HSV 포맷이 더 쉽습니다. 머신 러닝 모델은 입력 데이터에서 적절한 표현을 찾는 것입니다. 이런 데이터 변환은 분류 작업 같은 문제를 더 쉽게 해결할 수 있도록 만들어 줍니다.

구체적으로 살펴보죠. x축, y축이 있고 이 (x, y) 좌표 시스템으로 표현된 데이터 포인트가 그림 1-3에 나타나 있습니다.

032_1
그림 1-3 간단한 예시 데이터

그림에서 볼 수 있듯이 흰색 포인트와 빨간색 포인트가 있습니다. 포인트의 좌표 (x, y)를 입력으로 받고 그 포인트가 빨간색인지 흰색인지를 출력하는 알고리즘을 개발하려고 합니다. 이 경우에는 다음과 같이 요약할 수 있습니다.

입력은 포인트의 좌표입니다.
기대 출력은 포인트의 색깔입니다.
알고리즘의 성능을 측정하는 방법은 정확히 분류한 포인트의 비율을 사용하여 알고리즘의 성능을 측정합니다.
여기서 우리가 원하는 것은 흰색 포인트와 빨간색 포인트를 완벽하게 구분하는 새로운 데이터 표현입니다. 사용할 수 있는 변환 방법 중 하나는 그림 1-4와 같은 좌표 변환입니다.

032_2
그림 1-4 좌표 변환

포인트에 대한 새로운 좌표는 새로운 데이터 표현이라고 말할 수 있습니다. 그리고 좋은 표현을 찾았습니다. 이 표현을 사용하면 색깔 분류 문제를 “x > 0인 것은 빨간색 포인트다.” 또는 “x < 0인 것은 흰색 포인트다.”라는 간단한 규칙으로 나타낼 수 있습니다. 기본적으로 이 분류 문제를 해결한 것은 새로운 표현입니다.

이 경우에는 우리가 직접 좌표 변환을 정했습니다. 만약 시스템적으로 가능한 여러 좌표 변환을 찾아서 포인트 중 몇 퍼센트가 정확히 분류되었는지를 피드백으로 사용한다면, 바로 머신 러닝을 하고 있는 것입니다. 이처럼 머신 러닝에서의 학습Learning이란 더 나은 표현을 찾는 자동화된 과정입니다.

모든 머신 러닝 알고리즘은 주어진 작업을 위해 데이터를 더 유용한 표현으로 바꾸는 이런 변환을 자동으로 찾습니다. 이 연산은 앞서 본 좌표 변환일 수도 있고 또는 선형 투영linear projection(정보를 잃을 수 있음), 이동translation, 비선형 연산(예를 들어 x > 0인 모든 포인트를 선택하는 것) 등이 될 수도 있습니다. 머신 러닝 알고리즘은 일반적으로 이런 변환을 찾기 위한 창의력은 없습니다. 가설 공간hypothesis space이라 부르는 미리 정의된 연산의 모음들을 자세히 조사하는 것뿐입니다.

기술적으로 말하면 머신 러닝은 가능성 있는 공간을 사전에 정의하고 피드백 신호의 도움을 받아 입력 데이터에 대한 유용한 변환을 찾는 것입니다. 이 간단한 아이디어가 음성 인식에서부터 자율 주행 자동차까지 아주 다양한 분야에서 지능에 관한 문제를 해결합니다.

이제 학습이 의미하는 바를 이해했을 것입니다. 다음으로 무엇이 딥러닝을 특별하게 만드는지 살펴보겠습니다.

 

1.1.4 딥러닝에서 ‘딥’이란 무엇일까?
딥러닝은 머신 러닝의 특정한 한 분야로서 연속된 층layer에서 점진적으로 의미 있는 표현을 배우는 데 강점이 있으며, 데이터로부터 표현을 학습하는 새로운 방식입니다. 딥러닝의 딥deep이란 단어가 어떤 깊은 통찰을 얻을 수 있다는 것을 의미하지는 않습니다. 그냥 연속된 층으로 표현을 학습한다는 개념을 나타냅니다. 데이터로부터 모델을 만드는 데 얼마나 많은 층을 사용했는지가 그 모델의 깊이가 됩니다. 이 분야에 대한 적절한 다른 이름은 층 기반 표현 학습layered representations learning 또는 계층적 표현 학습hierarchical representations learning이 될 수 있습니다. 최근의 딥러닝 모델은 표현 학습을 위해 수십 개, 수백 개의 연속된 층을 가지고 있습니다. 이 층들을 모두 훈련 데이터에 노출해서 자동으로 학습시킵니다. 한편 다른 머신 러닝 접근 방법은 1~2개의 데이터 표현 층을 학습하는 경향이 있습니다. 그래서 이런 방식을 얕은 학습shallow learning이라 부르기도 합니다.

딥러닝에서는 기본 층을 겹겹이 쌓아 올려 구성한 신경망neural network이라는 모델을 (거의 항상) 사용하여 표현 층을 학습합니다. 신경망이란 단어는 신경 생물학의 용어입니다.5 딥러닝의 일부 핵심 개념이 뇌 구조를 이해하는 것에서부터 영감을 얻어 개발된 부분이 있지만, 딥러닝 모델이 뇌를 모델링한 것은 아닙니다. 최근의 딥러닝 모델이 사용하는 학습 메커니즘과 유사한 것을 뇌가 가지고 있다는 근거는 없습니다. 대중 과학 저널에서 딥러닝이 뇌처럼 작동한다거나 뇌를 모방하여 만들었다고 주장하는 글을 이따금 볼 수 있지만, 이는 사실이 아닙니다. 딥러닝이 신경 생물학과 어떤 관련이 있는 것처럼 생각하는 것이 오히려 이 분야를 처음 접하는 사람들을 혼란스럽게 해서 역효과를 냅니다. 인간의 정신 세계와 같은 신비하고 미스터리한 무언가를 떠올릴 필요가 없습니다. 이전에 읽었던 딥러닝과 생물학 사이를 연관 짓는 어떤 가설도 잊는 것이 좋습니다. 우리가 다루는 딥러닝은 그냥 데이터로부터 표현을 학습하는 수학 모델일 뿐입니다.

딥러닝 알고리즘으로 학습된 표현은 어떻게 나타날까요? 몇 개의 층으로 이루어진 네트워크(그림 1-5 참고)가 이미지 안의 숫자를 인식하기 위해 이미지를 어떻게 변환하는지 살펴보겠습니다.

034
그림 1-5 숫자 분류를 위한 심층 신경망deep neural network

그림 1-6에서 볼 수 있듯이 최종 출력에 대해 점점 더 많은 정보를 가지지만 원본 이미지와는 점점 더 다른 표현으로 숫자 이미지가 변환됩니다. 심층 신경망을 정보가 연속된 필터filter를 통과하면서 순도 높게(즉 어떤 작업에 대해서 유용하게) 정제되는 다단계 정보 추출 작업으로 생각할 수 있습니다.

035
그림 1-6 숫자 분류 모델에 의해 학습된 표현

바로 이것이 딥러닝입니다. 기술적으로는 데이터 표현을 학습하기 위한 다단계 처리 방식을 말합니다. 간단한 아이디어이지만, 매우 단순한 이 구조를 충분한 규모로 확장하면 마치 마술 같은 일을 할 수 있습니다.

 

1.1.5 그림 3개로 딥러닝의 작동 원리 이해하기
이제 머신 러닝이 많은 입력과 타깃target의 샘플을 관찰하면서 입력(예: 이미지)을 타깃(예: ‘고양이’ 레이블)에 매핑mapping하는 것임을 알았습니다. 심층 신경망은 이런 입력-타깃 매핑을 간단한 데이터 변환기(층)를 많이 연결하여 수행한다는 것도 배웠습니다. 이런 데이터 변환은 샘플에 노출됨으로써 학습이 이루어집니다. 이제 어떻게 이런 학습이 일어나는지 자세히 살펴봅시다.

층에서 입력 데이터가 처리되는 상세 내용은 일련의 숫자로 이루어진 층의 가중치weight에 저장되어 있습니다. 기술적으로 말하면 어떤 층에서 일어나는 변환은 그 층의 가중치를 파라미터parameter로 가지는 함수로 표현됩니다(그림 1-7 참고). (이따금 가중치를 그 층의 파라미터라고도 부릅니다.6) 이런 맥락으로 보면 학습은 주어진 입력을 정확한 타깃에 매핑하기 위해 신경망의 모든 층에 있는 가중치 값을 찾는 것을 의미합니다. 하지만 어떤 심층 신경망은 수천만 개의 파라미터를 가지기도 합니다. 이런 경우에 모든 파라미터의 정확한 값을 찾는 것은 어려운 일로 보입니다. 파라미터 하나의 값을 바꾸면 다른 모든 파라미터에 영향을 끼치기 때문입니다!

036_1
그림 1-7 신경망은 가중치를 파라미터로 가진다

어떤 것을 조정하려면 먼저 관찰해야 합니다. 신경망의 출력을 제어하려면 출력이 기대하는 것보다 얼마나 벗어났는지를 측정해야 합니다. 이는 신경망의 손실 함수loss function 또는 목적 함수objective function가 담당하는 일입니다.7 신경망이 한 샘플에 대해 얼마나 잘 예측했는지 측정하기 위해 손실 함수가 신경망의 예측과 진짜 타깃(신경망의 출력으로 기대하는 값)의 차이를 점수로 계산합니다(그림 1-8 참고).

036_2
그림 1-8 손실 함수가 신경망의 출력 품질을 측정
기본적인 딥러닝 방식은 이 점수를 피드백 신호로 사용하여 현재 샘플의 손실 점수가 감소되는 방향으로 가중치 값을 조금씩 수정하는 것입니다(그림 1-9 참고). 이런 수정 과정은 딥러닝의 핵심 알고리즘인 역전파Backpropagation 알고리즘을 구현한 옵티마이저optimizer가 담당합니다. 다음 장에서 역전파가 어떻게 작동하는지 상세하게 설명하겠습니다.

초기에는 네트워크의 가중치가 랜덤한 값으로 할당되므로 랜덤한 변환을 연속적으로 수행합니다. 자연스럽게 출력은 기대한 것과 멀어지고 손실 점수가 매우 높을 것입니다. 하지만 네트워크가 모든 샘플을 처리하면서 가중치가 조금씩 올바른 방향으로 조정되고 손실 점수가 감소합니다. 이를 훈련 반복training loop이라고 하며, 충분한 횟수만큼 반복하면(일반적으로 수천 개의 샘플에서 수십 번 반복하면) 손실 함수를 최소화하는 가중치 값을 산출합니다. 최소한의 손실을 내는 네트워크가 타깃에 가능한 가장 가까운 출력을 만드는 모델이 됩니다. 다시 한 번 말하지만 이 간단한 메커니즘이 확장되면 마술 같은 결과를 만듭니다.

 

1.1.6 지금까지 딥러닝의 성과
딥러닝은 머신 러닝의 오래된 하위 분야이지만 2010년 초가 되어서야 유명해졌습니다. 이때부터 몇 년 동안 이 분야에서 일어난 혁신은 결코 작지 않습니다. 사람에게는 자연스럽고 직관적으로 보이지만 기계로는 오랫동안 해결하기 어려웠던 시각과 청각 같은 지각의 문제에서 괄목할 만한 성과를 냈습니다.

특히 딥러닝은 다음과 같은 획기적인 발전을 이루었습니다. 모두가 머신 러닝에서는 오랫동안 어려운 문제였습니다.

사람과 비슷한 수준의 이미지 분류
사람과 비슷한 수준의 음성 인식
사람과 비슷한 수준의 필기 인식
향상된 기계 번역
향상된 TTSText-To-Speech 변환
구글 나우Now와 아마존 알렉사Alexa 같은 디지털 비서
사람과 비슷한 수준의 자율 주행 능력
구글, 바이두Baidu, 빙Bing에서 사용하는 향상된 광고 타기팅targeting 8
향상된 웹 검색 엔진의 결과
자연어 질문에 대답하는 능력
사람을 능가하는 바둑 실력
우리는 여전히 딥러닝이 할 수 있는 일의 전체 크기를 알아 가는 중입니다. 지각과 자연어 인식 외 에 형식 추론formal reasoning 9과 같은 다양한 문제에 적용하기 시작했습니다. 만약 성공한다면 딥러닝이 과학, 소프트웨어 개발 등에서 사람을 보조하게 되는 시대를 알리는 것일지도 모릅니다.

 

1.1.7 단기간의 과대 선전을 믿지 말자
딥러닝이 최근 몇 년간 놀라운 성과를 이끌어 냈지만, 사람들이 향후 10년 안에 기대하는 성과는 가능한 것보다 훨씬 높은 편입니다. 자율 주행 자동차 같은 세상을 바꿀 만한 몇 가지 애플리케이션은 이미 가까이 다가왔지만, 신뢰할 만한 대화 시스템이나 사람 수준의 기계 번역 그리고 사람 수준의 자연어 이해처럼 더 많은 것이 오랫동안 어려운 문제로 남아 있을 것 같습니다. 특히 사람 수준의 일반 지능general intelligence에 관한 이야기는 너무 심각하게 다루지 않는 것이 좋습니다. 단기간에 많이 성장할 것이라고 큰 기대를 하는 것은 위험합니다. 기술이 문제를 해결하지 못하면 연구에 대한 투자가 크게 줄어들고 발전은 오랫동안 정체될 것입니다.

예전에도 이런 일이 있었습니다. 과거에도 AI는 장밋빛 전망 뒤에 이어진 실망과 회의의 사이클을 두 번이나 경험했고, 결국 투자의 감소로 이어졌습니다. 1960년대 심볼릭 AI가 그 시작이었습니다. 초창기에 심볼릭 AI에 대한 기대는 매우 높았습니다. 심볼릭 AI 방법에 관한 가장 유명한 개척자이자 지지자 중 한 명인 마빈 민스키Marvin Minsky는 1967년에 “이번 세대 안에 …… ‘인공 지능’을 만드는 문제는 거의 해결될 것입니다.”라고 주장했습니다. 3년 후인 1970년에는 더 정확하게 정량화된 예측을 했습니다. “3년에서 8년 이내에 평균적인 사람 수준의 일반 지능을 가진 기계가 나올 것입니다.” 2016년에도 그런 성과는 여전히 먼 미래의 일로 보입니다. 아직까지 얼마나 오래 걸릴지 예측하는 방법조차 없습니다. 하지만 1960년대와 1970년대 초에는 몇몇 전문가들이 바로 근시일 안에 문제가 해결될 것이라고 믿었습니다(오늘날에도 많은 사람이 그렇습니다). 몇 년 후에 이런 높은 기대가 구체화되지 못하자 연구자들과 정부 자금은 이 분야에 대한 투자를 줄였고, 첫 번째 AI 겨울AI winter이 시작되었습니다(이는 냉전Cold War이 절정에 다다른 후에 나타나는 핵 겨울nuclear winter에 대한 비유입니다10).

이것이 마지막이 아니었습니다. 1980년대에 심볼릭 AI의 새로운 버전인 전문가 시스템expert system이 큰 기업들 사이에서 인기를 끌기 시작했습니다. 초창기 몇 개의 성공적인 스토리가 투자의 물결을 이끌었고, 전 세계 회사들이 전문가 시스템을 구축하기 위해 내부에 AI 부서를 꾸리기 시작했습니다. 1985년 즈음에 회사들은 이 기술에 연간 10억 달러 이상을 사용했습니다. 하지만 1990년대 초기에 이 시스템은 유지 비용이 비싸고, 확장하기 어려우며 제한된 범위를 가진다는 것이 증명되었고 관심은 사그라들었습니다. 이로 인해 두 번째 AI 겨울이 시작되었습니다. 우리는 현재 AI의 과대 선전과 실망의 세 번째 사이클을 목격하고 있는지도 모릅니다. 아직까지는 매우 낙관적인 단계입니다. 단기간의 기대를 조금 누그러뜨리고, 이 분야의 기술적 측면을 잘 모르는 사람들에게 딥러닝이 할 수 있는 것과 할 수 없는 것에 대해 명확히 이해시키는 것이 좋습니다.

 

1.1.8 AI에 대한 전망
AI에 대한 단기간의 기대는 비현실적일지도 모르지만, 장기적인 전망은 매우 밝습니다. 의료 진단에서부터 디지털 비서까지 확실히 이전과는 다른 여러 중요한 문제에 딥러닝을 적용하기 시작했습니다. AI 역사상 유례를 찾아볼 수 없는 수준의 투자에 크게 힘입어 AI 연구는 지난 5년간 놀라울 정도로 매우 빠르게 발전해 왔습니다. 하지만 이런 발전 중에서 비교적 아주 일부만이 현실 세계의 제품과 프로세스에 적용되었습니다. 딥러닝 연구 성과의 대부분은 아직 적용되지 않았거나, 적어도 전체 산업계를 통틀어서 딥러닝이 풀 수 있는 다양한 종류의 문제에는 적용되지 않았습니다. 일반 의사들은 아직 AI를 사용하지 않고, 회계사들도 마찬가지입니다. 아마 여러분도 일상생활에서 AI 기술을 사용하지 않고 있을 것입니다. 물론 스마트폰에 간단한 질문을 해서 그럴싸한 대답을 얻거나 아마존닷컴Amazon.com에서 유용한 상품 추천을 받고, 구글 포토Google Photos에서 ‘생일’을 검색해서 지난달의 딸아이 생일 파티 사진을 바로 찾을 수 있습니다. 이런 기술은 이전에 비해 많이 발전되었습니다. 하지만 이런 도구는 여전히 우리 일상생활의 액세서리일 뿐입니다. AI는 우리가 일하고 생각하고 생활하는 것의 중심에 들어오지 않았습니다.

AI가 아직 폭넓게 적용되지 못했기 때문에 지금 당장은 AI가 이 세상에 큰 영향을 줄 수 있으리라고 믿기 힘들지도 모릅니다. 비슷하게 1995년으로 돌아가 보면, 그때는 인터넷이 미래에 미칠 영향을 믿기 힘들었을 것입니다. 그 당시에 대부분의 사람들은 인터넷이 자신과 어떻게 연관이 있을지, 우리의 일상생활을 어떻게 바꿀지 이해하지 못했습니다. 오늘날 딥러닝과 AI도 동일합니다. 그러므로 실수를 범하지 말아야 합니다. 결국 AI의 시대는 도래할 것입니다. 그리 멀지 않은 미래에 AI가 우리의 비서가 되고, 심지어 친구가 될 것입니다. 우리의 질문에 대답하고 아이의 교육을 도와주고 건강을 보살펴 줄 것입니다. 식료품을 문 앞에 배달해 주고 A부터 B 지점까지 차를 운전해 줄 것입니다. 점점 더 복잡해지고 정보가 넘쳐 나는 세상에 대한 인터페이스interface가 될 것입니다. 더욱 중요한 것은 AI가 유전학에서부터 수학까지 모든 분야의 과학자들을 도와 새롭고 놀라운 발견을 이루어 냄으로써 인류 전체를 발전시킬 것이란 점입니다.

이 와중에 몇 번의 난관을 만날 수 있고 새로운 AI 겨울이 올 수도 있습니다. 마치 인터넷 업계가 1998~1999년 사이에 매우 과열되었다가 2000년대 초에 몰락하면서 투자가 멈추어 고통을 받았던 것과 같습니다. 하지만 결국 AI 시대는 올 것입니다. 오늘날의 인터넷처럼 우리 사회와 일상생활을 구성하는 거의 모든 과정에 AI가 적용될 것입니다.

단기간의 과대 선전은 믿지 말고 장기 비전을 믿으세요. AI가 아직 아무도 감히 생각하지도 못했던 완전한 모습으로 진정한 잠재성을 발휘하려면 어느 정도의 시간이 걸릴지 아무도 모릅니다. 하지만 AI의 시대는 올 것이고 이 세상을 환상적인 방식으로 변모시킬 것입니다.

 

 

역주 영국의 시인 조지 고든 바이런George Gordon Byron의 딸이며, 그녀가 해석 기관의 논문에 추가한 베르누이 수를 구하는 알고리즘 이 최초의 프로그램으로 인정되어 최초의 프로그래머라고 불립니다. 1980년 미국 국방성은 기존 언어를 대체하려고 만든 새 프로그램 언어에 그녀의 이름을 따서 에이다Ada란 이름을 붙였습니다.
A. M. Turing, “Computing Machinery and Intelligence,” Mind 59, no. 236 (1950): 433-460. (https://goo.gl/ZiXntw)
역주 튜링은 이 논문에서 러브레이스의 반론을 포함하여 총 9개의 반론에 대한 답변을 기술했습니다.
역주 NIPS 2017에서 구글의 알리 라히미Ali Rahimi가 이를 연금술Alchemy에 비유(https://goo.gl/ajtvhX)해서 얀 르쿤Yann LeCun 박사와 다소 설전이 있기도 했습니다. 대부분의 사람들은 연금술이란 단어에 대해 우호적인 편이지만 여기서는 이론적 배경이 부족 하다는 것을 꼬집는 말입니다.
역주 종종 머신 러닝의 신경망을 인공 신경망artificial neural network으로, 생물학의 신경망을 생물학적 신경망biological neural network으로 구분하여 부르기도 합니다. 이 책에서는 신경망neural network과 네트워크network를 혼용하여 사용하고 있습니다. 저자 의 의도를 살리고 신경망이 진짜 ‘신경’과 관련 있다는 오해를 줄이기 위해 문맥상 어색하지 않다면 ‘network’는 그대로 ‘네트워크’라고 옮겼 습니다.
역주 이런 파라미터를 모델 파라미터라고도 합니다. 이 책에서는 혼동을 피하기 위해 파이썬 프로그램의 함수와 클래스에 전달할 때 사용하는 파라미터는 매개변수로 번역합니다.
역주 또는 비용 함수cost function라고도 부릅니다. 정확하게 말하면 비용 함수는 모든 훈련 데이터에 대한 손실 함수의 합을 나타내고 목적 함수는 더 일반적인 용어로 최적화하기 위한 대상 함수를 의미합니다. 보통 이 세 가지 용어를 크게 구분하지 않고 혼용하여 사용하는 경우가 많습니다.
역주 구글과 페이스북이 가장 진보된 온라인 광고 기술을 보유하고 있고 많은 머신 러닝 알고리즘을 광고의 타기팅과 최적화에 접목하고 있습니다.
역주 논리학에서 추론 규칙에 따라 새로운 논리식이나 규칙을 검사하는 방법입니다(출처: 국립국어원 우리말샘 사전).
역주 핵 겨울은 천문학자 칼 세이건Carl Sagan 등이 1983년에 주장한 것으로 핵 전쟁으로 대규모 환경 변화가 발생하여 지구에 빙하기 가 온다는 가설입니다.
 

베타테스터 실습 후기 | 목차 | 1.2 딥러닝 이전: 머신 러닝의 간략한 역사

 

이 글은 도서출판 길벗에서 출간한  “케라스 창시자에게 배우는 딥러닝“의 1장~3장입니다. 이 책의 저작권은 (주)도서출판 길벗에 있으므로 무단 복제 및 무단 전제를 금합니다.
이 글 공유하기:
트위터Facebook

답글 남기기
여기에 댓글을 입력하세요...
This site uses Akismet to reduce spam. Learn how your comment data is processed.

검색:
 
홍대 머신러닝 스터디
홍대 머신러닝 스터디

- 어떤 책을 봐야 하나요?
- 도서 에러타 메일링 리스트

'핸즈온 머신러닝 2판' 출간(errata)
핸즈온 머신러닝 2판

'미술관에 GAN 딥러닝' 출간(errata)
미술관에 GAN 딥러닝
★★★★★ AI관련 번역책을 10권 정도 샀었는데 그중 단연코 최고 였습니다.(eksis 님)
★★★★★ GAN에 대해 이만큼 친절하게 설명해준 책이 또 있었나 싶을 정도이다(aetty 님)
♥♥♥♥ GAN을 어렵지 않게 재미있게 설명해주는 책입니다.(ky**oo 님)

'Do it! 딥러닝 입문' 출간(errata)
Do it! 딥러닝 입문
★★★★★ 딥러닝을 배우고자 하는분께 강추합니다!(wtiger85 님)
★★★★★ 강추. 박해선님의 책은 일단 지른 다음에 생각합니다.(heistheguy 님)
♥♥♥♥ 코랩을 사용한 딥러닝을 알려주는 책 매우 유용합니다.(su**rss007 님)

'파이썬을 활용한 머신러닝 쿡북' 출간(errata)
파이썬을 활용한 머신러닝 쿡북
★★★★★ 좋은 내용, 멋진번역이네요(s9055038 님)
★★★★★ 머신러닝 전문가의 참고도서!(kjooh0220 님)
♥♥♥♥ 데이터사이언스 전처리 실무를 다루는 끝판왕!(na**mjjang 님)

'머신 러닝 교과서' 출간(errata)
머신러닝 교과서
♥♥♥♥ 아마존 베스트셀러 라는 명성이 왜 생겼는지 알 수 있는 좋은 책임(mo**buggy 님)
★★★★★ 진정한 머신러닝 교과서! 그리고 파이썬-(coolcat 님)
★★★★★ 마치 한국어판이 원서인 것처럼 군더더기 없이 완벽한 번역서(yeonwo*** 님)

"[개정판] 파이썬 라이브러리를 활용한 머신러닝" 출간 (errata)
파이썬 라이브러리를 활용한 머신러닝
★★★★★ 검증된 내용, 훌륭한 번역자, 그리고 좋은 편집(hawkm*** 님)
★★★★ 개정판은 인기없는 책은 나올 이유가 없다(ghcjs*** 님)
♥♥♥♥ 올 컬러로 깔끔한 해설(bi**cle2 님)

'케라스 창시자에게 배우는 딥러닝' 출간 (errata)
deep learning with python
홍정모 교수님의 도서 리뷰 영상
★★★★★ 번역자는 이 책의 가장 큰 장점입니다.(mo**05 님)
★★★★★ 박해선님 이 분야 기술 번역은 최고 ^^ ..(sa**ke 님)
♥♥♥♥ 인공지능에 대해 알고 싶은 분이라면 추천드려요~(lj**999 님)
★★★★★ 이론과 코드를 함께 제공하는 아주 좋은 케라스 입문서(정*준 님)

'핸즈온 머신러닝' 출간(errata)
hands-on machine learning with scikit-learn & tensorflow
★★★★★ 제가 본 한국어로 된 ML책중에서 최고의 기량을 갖추었습니다.(bk**ys 님)
♥♥♥♥ 좋은 책입니다. 꼭 읽어봅시다.(we**lifema 님)
★★★★ 현존하는 머신러닝 책중 최고.(wnghdcjfe 님)
★★★★★ 머신러닝/딥러닝계의 바이블이라고 생각합니다!(Kebee 님)
★★★★★ 책장에 꽂아두고 마르고 닳도록 꺼내 보는 그러한 책인 것이다.(dragmove 님)

'파이썬 라이브러리를 활용한 머신러닝' 출간(errata)
파이썬 라이브러리를 활용한 머신러닝
★★★★★ 정말 많은 머신러닝책을 봤다. 이 책이 당연 최고다.(red***** 님)
★★★★☆ 머신러닝을 실제로 활용하고 싶다면 반드시 읽어야할 책!(pa**3424 님)
♥♥♥♡ 머신러닝과 인공지능에 대한 입문서로, 파이썬과 사이킷런을 중심으로 머신러닝 애플리케이션을 만드는 모든 단계를 배우는데 유용 합니다.(sa**huh 님)
★★★★★ 저에겐 은인 같은 책입니다.(tac*** 님)

'텐서플로 첫걸음' 출간(Errata)
텐서플로 첫걸음

사이킷런 코리아
사이킷런 코리아
이메일로 블로그 팔로우
이 블로그를 팔로우하고 새 글 알림을 이메일로 받으려면 이메일 주소를 입력하세요.

다른 546명의 팔로워와 함께하세요.

이메일 주소 입력

팔로우

– 넘파이 튜토리얼
– Model evaluation, model selection
– 네스테로프 == 모멘텀 of 모멘텀
– 해커에게 전해들은 머신러닝
– 해커가 알려주는 뉴럴 네트워크
– 딥러닝을 위한 콘볼루션 계산 가이드
– First Contact with TensorFlow 번역

– [Preview]Fundamental of Deep Learning

인기 글
윈도우즈에 아나콘다, 텐서플로 설치하기
1. 딥러닝이란 무엇인가?
파이썬 머신러닝
1. 텐서플로우 기본다지기 - First Contact with TensorFlow
머신 러닝의 모델 평가와 모델 선택, 알고리즘 선택 - 1장. 기초
1.3 머신러닝 시스템의 종류
2.3.7 커널 서포트 벡터 머신
어떤 책을 봐야 하나요?
3.6 주택 가격 예측: 회귀 문제
2.3.6 결정 트리의 앙상블
최근 글
케라스 2.4.0 버전이 릴리스되었습니다. 2020-06-18
유튜브 동영상 강의 안내 2020-05-30
“[개정판] 파이썬 라이브러리를 활용한 머신러닝” 사이킷런 0.23 업데이트 2020-05-27
[핸즈온 머신러닝 2], [파이썬을 활용한 머신러닝 쿡북], [머신러닝 교과서] 사이킷런 0.23 업데이트 안내 2020-05-22
TensorFlow 2.2의 사용자 정의 훈련 반복 2020-05-14
Scikit-Learn 0.23.0 Release! 2020-05-13
[Do It! 딥러닝 입문], [파이썬을 활용한 머신러닝 쿡북], [머신러닝 교과서] 텐서플로 2.2.0 업데이트 안내 2020-05-08
TensorFlow 2.2.0 Release 2020-05-08
[독서 후기] 은밀한 설계자들 2020-05-02
핸즈온 머신러닝 2판의 변경 부분 2020-05-01
‘핸즈온 머신러닝 2판’이 출간되었습니다! 2020-04-14
핸즈온 머신러닝 2/E 번역 후기 2020-03-28
TensorFlow 2.2.0 RC0 Release 2020-03-11
TensorFlow 2.1.0 Release 2020-01-13
Python Machine Learning 3/E !!! 2019-12-13
최근 댓글
	박해선 (머신 러닝의 모델 평가와 모델 선택, 알고리즘 선택…)
	김지응 (머신 러닝의 모델 평가와 모델 선택, 알고리즘 선택…)
	조이림 (윈도우즈에 아나콘다, 텐서플로 설치하기)
	박해선 (윈도우즈에 아나콘다, 텐서플로 설치하기)
	조이림 (윈도우즈에 아나콘다, 텐서플로 설치하기)
	감사합니다 (‘핸즈온 머신러닝 2판’이…)
	박해선 (핸즈온 머신러닝 2/E 번역 후기)
	박해선 (핸즈온 머신러닝 2/E 번역 후기)
	yscs (핸즈온 머신러닝 2/E 번역 후기)
	박해선 (‘핸즈온 머신러닝 2판’이…)
	박해선 (‘핸즈온 머신러닝 2판’이…)
	감사합니다 (‘핸즈온 머신러닝 2판’이…)
	박해선 (TensorFlow 2.2.0 RC0 Rele…)
	fageapp (TensorFlow 2.2.0 RC0 Rele…)
	박해선 (윈도우즈에 아나콘다, 텐서플로 설치하기)
카테고리
Book (37)
Conference (22)
Data Science (3)
Deep Learning (266)
Google Gloud (1)
사이킷런 정주행 (1)
핸즈온 머신러닝 (4)
Keras (14)
Lecture (55)
Machine Learning (89)
News (272)
Paper (10)
Python (26)
PyTorch (17)
Reinforcement Learning (2)
Report (30)
scikit-learn (35)
TensorFlow (160)
Theano (1)
AI Andrej Karpathy Andrew Ng Book CNTK Coursera Deep Learning DeepMind Facebook François Chollet Google Gym Ian Goodfellow Keras Machine Learning Microsoft Nvidia OpenAI Paper Python PyTorch Reinforcement Learning scikit-learn Stanford TensorFlow Torch Tutorial Yann LeCun Yoshua Bengio 핸즈온 머신러닝
Book Conference Data Science Deep Learning Google Gloud Keras Lecture Machine Learning News Paper Python PyTorch Reinforcement Learning Report scikit-learn TensorFlow Theano 사이킷런 정주행 핸즈온 머신러닝
글 목록
2020년 6월 (1)
2020년 5월 (9)
2020년 4월 (1)
2020년 3월 (2)
2020년 1월 (1)
2019년 12월 (1)
2019년 11월 (3)
2019년 10월 (3)
2019년 9월 (3)
2019년 8월 (3)
2019년 7월 (2)
2019년 6월 (3)
2019년 5월 (8)
2019년 4월 (1)
2019년 3월 (6)
2019년 2월 (9)
2019년 1월 (1)
2018년 12월 (1)
2018년 11월 (6)
2018년 10월 (6)
2018년 9월 (6)
2018년 8월 (5)
2018년 7월 (3)
2018년 6월 (3)
2018년 5월 (3)
2018년 4월 (5)
2018년 3월 (6)
2018년 2월 (4)
2018년 1월 (4)
2017년 12월 (6)
2017년 11월 (4)
2017년 10월 (4)
2017년 9월 (3)
2017년 8월 (7)
2017년 7월 (6)
2017년 6월 (10)
2017년 5월 (10)
2017년 4월 (11)
2017년 3월 (21)
2017년 2월 (16)
2017년 1월 (21)
2016년 12월 (15)
2016년 11월 (14)
2016년 10월 (19)
2016년 9월 (30)
2016년 8월 (31)
2016년 7월 (20)
2016년 6월 (33)
2016년 5월 (36)
2016년 4월 (24)
2016년 3월 (7)
2016년 2월 (1)
2016년 1월 (8)
2015년 12월 (9)
2015년 11월 (4)
RSS - 글
RSS - 댓글
블로그 통계
3,050,679 hits
Copyright © 2015 tensorflow.blog
TensorFlow, the TensorFlow logo and any related marks are trademarks of Google Inc.

:)