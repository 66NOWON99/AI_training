data = pd.read_csv("./data-03-diabetes.csv", sep=",", names = ['A','B','C','D','E','F','G','H','I'])
data.head

x_data = data[['A','B','C','D','E','F','G','H']]
y_data = data[['I']]

X = tf.placeholder(tf.float32, shape=[None, 8])
Y = tf.placeholder(tf.float32, shape=[None, 1])

W = tf.Variable(tf.random_normal([8,1]), name='weight')
b = tf.Variable(tf.random_normal([1]), name='bias')

hypothesis = tf.sigmoid(tf.matmul(X,W) + b) # 1.0 / (1 + tf.exp(-(tf.matmul(X,W) + b)))
cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))
# 엔트로피 (0, 1에서 0, 0.5에서 1의 값을 가짐. 반원 모양 그래프, 맞으면 0에 가까운 값, 틀리면 무한대에 가까운 값)

train = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(cost)
predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32) # True -> 1, False -> 0으로 캐스팅
accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32)) # 같으면 -> 1, 다르면 -> 0으로 캐스팅

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    
    for step in range(100001):
        cost_val, _ = sess.run([cost, train], feed_dict={X:x_data, Y:y_data})
        if step % 2000 == 0:
            print(step, cost_val)
            
    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X:x_data, Y:y_data})
    print("\nHypothesis : \n",h, "\nPredicted : \n", c, "\nAccuracy : ", a)
    # 이 파라미터에서는 Accuracy :  0.7773386