ex1_ = np.loadtxt("./ex1.txt")
ex1_[:10]

ex1_.shape

# x의 첫번째 피쳐를 bias로 사용하는 경우
x_data = ex1_[:,0:2]
y_data = ex1_[:,2]

with tf.Graph().as_default():
    x = tf.placeholder(tf.float32, shape=[None,2]) #예제의 갯수는 상관없음 x feature 갯수만 2개로 고정
    y = tf.placeholder(tf.float32, shape=None)
    
    w = tf.Variable([[0,0]], dtype=tf.float32, name='weight') #가중치,오차 초기값 0
    # b = tf.Variable(0, dtype=tf.float32, name='bias')
    
    y_hat = tf.matmul(w, tf.transpose(x)) # + b
    
    loss = tf.reduce_mean(tf.square(y - y_hat)) #잔차 제곱의 평균, 학습되는 기준이므로 loss function이 굉장히 중요함
    
    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.005)
    #이 파라미터 값으로는 [array([[3.0078063, 1.6685958]], dtype=float32)]이 근사 최적해임
    # MLR의 hyper parameter = learning rate, epoch
    train = optimizer.minimize(loss)
    
    init = tf.global_variables_initializer()
    with tf.Session() as sess:
        sess.run(init)
        for step in range(100000): #epoch = 100000
            sess.run(train, feed_dict={x:x_data, y:y_data})
            if(step % 5000 == 0):
                print(step, sess.run([w]))
        print(step, sess.run([w]))